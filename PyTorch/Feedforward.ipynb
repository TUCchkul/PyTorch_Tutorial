{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device Config\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "input_size=784\n",
    "hidden_size=100\n",
    "num_classes=10\n",
    "num_epochs=10\n",
    "batch_size=100\n",
    "learning_rate=0.001\n",
    "train_dataset=torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset=torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "examples=iter(train_loader)\n",
    "samples,labels=examples.next()\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "#for i in range(6):\n",
    "#    plt.subplot(2,3, i+1)\n",
    "#    plt.imshow(samples[i][0], cmap='gray')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 10, step 100/600, loss=0.4104\n",
      "epoch 1 / 10, step 200/600, loss=0.4066\n",
      "epoch 1 / 10, step 300/600, loss=0.2853\n",
      "epoch 1 / 10, step 400/600, loss=0.3650\n",
      "epoch 1 / 10, step 500/600, loss=0.2314\n",
      "epoch 1 / 10, step 600/600, loss=0.2009\n",
      "epoch 2 / 10, step 100/600, loss=0.2881\n",
      "epoch 2 / 10, step 200/600, loss=0.1835\n",
      "epoch 2 / 10, step 300/600, loss=0.1467\n",
      "epoch 2 / 10, step 400/600, loss=0.2575\n",
      "epoch 2 / 10, step 500/600, loss=0.1508\n",
      "epoch 2 / 10, step 600/600, loss=0.1050\n",
      "epoch 3 / 10, step 100/600, loss=0.0729\n",
      "epoch 3 / 10, step 200/600, loss=0.1739\n",
      "epoch 3 / 10, step 300/600, loss=0.1467\n",
      "epoch 3 / 10, step 400/600, loss=0.1205\n",
      "epoch 3 / 10, step 500/600, loss=0.1518\n",
      "epoch 3 / 10, step 600/600, loss=0.1133\n",
      "epoch 4 / 10, step 100/600, loss=0.0525\n",
      "epoch 4 / 10, step 200/600, loss=0.1592\n",
      "epoch 4 / 10, step 300/600, loss=0.1387\n",
      "epoch 4 / 10, step 400/600, loss=0.0709\n",
      "epoch 4 / 10, step 500/600, loss=0.0879\n",
      "epoch 4 / 10, step 600/600, loss=0.0613\n",
      "epoch 5 / 10, step 100/600, loss=0.0822\n",
      "epoch 5 / 10, step 200/600, loss=0.0464\n",
      "epoch 5 / 10, step 300/600, loss=0.0907\n",
      "epoch 5 / 10, step 400/600, loss=0.0921\n",
      "epoch 5 / 10, step 500/600, loss=0.0356\n",
      "epoch 5 / 10, step 600/600, loss=0.0785\n",
      "epoch 6 / 10, step 100/600, loss=0.0653\n",
      "epoch 6 / 10, step 200/600, loss=0.0277\n",
      "epoch 6 / 10, step 300/600, loss=0.0511\n",
      "epoch 6 / 10, step 400/600, loss=0.1020\n",
      "epoch 6 / 10, step 500/600, loss=0.0399\n",
      "epoch 6 / 10, step 600/600, loss=0.0438\n",
      "epoch 7 / 10, step 100/600, loss=0.1179\n",
      "epoch 7 / 10, step 200/600, loss=0.0549\n",
      "epoch 7 / 10, step 300/600, loss=0.0404\n",
      "epoch 7 / 10, step 400/600, loss=0.0829\n",
      "epoch 7 / 10, step 500/600, loss=0.0186\n",
      "epoch 7 / 10, step 600/600, loss=0.0383\n",
      "epoch 8 / 10, step 100/600, loss=0.0464\n",
      "epoch 8 / 10, step 200/600, loss=0.0152\n",
      "epoch 8 / 10, step 300/600, loss=0.1156\n",
      "epoch 8 / 10, step 400/600, loss=0.0479\n",
      "epoch 8 / 10, step 500/600, loss=0.1164\n",
      "epoch 8 / 10, step 600/600, loss=0.0836\n",
      "epoch 9 / 10, step 100/600, loss=0.0380\n",
      "epoch 9 / 10, step 200/600, loss=0.1072\n",
      "epoch 9 / 10, step 300/600, loss=0.0383\n",
      "epoch 9 / 10, step 400/600, loss=0.0413\n",
      "epoch 9 / 10, step 500/600, loss=0.0619\n",
      "epoch 9 / 10, step 600/600, loss=0.0470\n",
      "epoch 10 / 10, step 100/600, loss=0.0218\n",
      "epoch 10 / 10, step 200/600, loss=0.0274\n",
      "epoch 10 / 10, step 300/600, loss=0.0636\n",
      "epoch 10 / 10, step 400/600, loss=0.0611\n",
      "epoch 10 / 10, step 500/600, loss=0.0431\n",
      "epoch 10 / 10, step 600/600, loss=0.0572\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1=nn.Linear(input_size, hidden_size)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.l2=nn.Linear(hidden_size, num_classes)\n",
    "    def forward(self, x):\n",
    "        out=self.l1(x)\n",
    "        out=self.relu(out)\n",
    "        out=self.l2(out)\n",
    "        return out\n",
    "model=NeuralNet(input_size,hidden_size,num_classes)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#training_loop\n",
    "n_total_steps=len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images=images.reshape(-1,28*28).to(device)\n",
    "        labels=labels.to(device)\n",
    "        #forward\n",
    "        outputs=model(images)\n",
    "        loss=criterion(outputs,labels)\n",
    "        #backwards\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print the loss\n",
    "        if (i+1)%100==0:\n",
    "            print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss={loss.item():.4f}')\n",
    "# test\n",
    "with torch.no_grad():\n",
    "    n_correct=0\n",
    "    n_samples=0\n",
    "    for images,labels in test_loader:\n",
    "        images=images.reshape(-1, 28*28).to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs=model(images)\n",
    "        #value, index\n",
    "        _,predictions=torch.max(outputs,1)\n",
    "        n_samples=labels.shape[0]\n",
    "        n_correct=(predictions==labels).sum().item()\n",
    "acc=100.0*n_samples/n_samples\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
