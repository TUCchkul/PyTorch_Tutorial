{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Conv_layers: [Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False), Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False), Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False), Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)] \n",
      "\n",
      "VGG_Net(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU()\n",
      "    (13): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU()\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU()\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU()\n",
      "    (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU()\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU()\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU()\n",
      "    (33): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU()\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU()\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU()\n",
      "    (43): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fully_connected_layers): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 512, 7, 7])\n",
      "X in Forward after reshape:tensor([[0.9008, 1.8508, 1.7842,  ..., 1.3970, 0.0000, 0.5489]],\n",
      "       grad_fn=<ReshapeAliasBackward0>) \n",
      "In forward layer: tensor([[-1.9260e-02, -3.7283e-02,  1.5777e-01,  2.4417e-03, -2.0107e-01,\n",
      "         -2.5123e-01, -3.4859e-01, -3.3176e-02,  1.0364e-01,  2.3844e-01,\n",
      "          1.4851e-01, -2.9187e-01, -7.6911e-02,  1.1375e-01,  3.1249e-01,\n",
      "          3.6408e-01,  5.3113e-01,  2.1770e-01, -3.9687e-02, -4.6112e-02,\n",
      "         -2.4027e-01,  4.4628e-01, -5.6669e-02, -4.7910e-02, -4.8334e-02,\n",
      "          5.4316e-01,  1.0972e-01,  2.5207e-01,  2.5073e-01,  2.0425e-02,\n",
      "         -2.7452e-01, -1.0455e-01, -3.0328e-01,  1.4992e-01,  3.3525e-02,\n",
      "          2.8470e-02, -2.2020e-01,  5.0473e-02, -2.8538e-01, -9.4749e-02,\n",
      "          6.8803e-02, -4.7337e-01, -1.8750e-01,  1.4018e-01,  4.9926e-02,\n",
      "         -9.1213e-02,  1.8302e-01, -8.1197e-02,  3.1059e-01, -2.5303e-01,\n",
      "          2.2460e-01, -2.5750e-02, -1.7698e-01, -1.6977e-01,  1.1688e-01,\n",
      "          1.9897e-01,  1.8828e-01,  2.9368e-01,  1.9914e-01, -3.6219e-01,\n",
      "          4.2554e-01, -3.1955e-01,  2.3236e-01, -2.0666e-01,  1.8930e-01,\n",
      "         -5.3990e-02,  5.6130e-01,  1.3981e-01,  5.3553e-01, -8.1326e-02,\n",
      "          2.6715e-01, -1.2689e-01, -3.6866e-01, -2.4374e-01, -9.6942e-02,\n",
      "          3.0025e-01,  8.7439e-02,  1.0760e-01,  3.3668e-01,  1.3179e-01,\n",
      "          1.4150e-01,  2.0905e-01, -1.2214e-01, -1.4607e-01,  4.7391e-01,\n",
      "         -1.6303e-01,  1.2551e-02, -2.7520e-02,  4.6235e-03,  1.4982e-01,\n",
      "          1.4287e-01, -2.3197e-01, -2.9354e-02,  7.9173e-02,  5.6313e-02,\n",
      "         -1.1109e-01, -2.7535e-02, -2.8158e-01,  3.0018e-01,  1.9238e-01,\n",
      "         -3.7331e-01, -2.5438e-01,  2.4358e-01, -5.3344e-01,  4.0164e-01,\n",
      "         -1.8601e-02, -2.5237e-01, -1.3280e-01,  9.0709e-02, -1.0822e-01,\n",
      "          2.6314e-01,  2.3066e-01, -2.6814e-01,  8.0353e-02, -4.3914e-02,\n",
      "          3.4883e-02,  6.6769e-02,  1.6398e-01,  7.7155e-02,  2.6227e-01,\n",
      "          1.2105e-01,  1.2275e-01,  2.1793e-01,  1.3108e-01,  1.3350e-02,\n",
      "         -3.3011e-01,  2.7862e-01,  2.4918e-01, -1.6861e-01,  3.0813e-01,\n",
      "          1.4784e-01, -4.9673e-01,  3.3983e-02, -1.1897e-01,  1.2322e-01,\n",
      "          1.1329e-01, -4.6067e-01,  3.4759e-01, -1.7624e-01, -2.9642e-01,\n",
      "          4.6211e-01, -3.1015e-01, -1.5344e-01, -1.3824e-01,  2.6405e-01,\n",
      "         -6.2645e-02,  3.4169e-01,  3.1551e-01,  1.1060e-01,  5.3015e-02,\n",
      "          2.9805e-01,  5.4994e-02, -8.8756e-02,  6.9033e-02,  5.6584e-01,\n",
      "         -1.5290e-01, -3.7639e-01,  1.5359e-01,  2.8665e-02,  2.9922e-01,\n",
      "         -5.8795e-03,  3.8447e-01, -2.1544e-02,  4.2503e-02, -1.1061e-01,\n",
      "         -2.4571e-01,  6.6484e-02,  2.5491e-01, -4.4853e-02, -4.7622e-01,\n",
      "         -2.9182e-01, -2.5962e-01, -1.6295e-01,  3.7105e-01, -4.9126e-01,\n",
      "         -4.2107e-01, -1.8405e-02, -1.0519e-01,  2.4190e-01, -2.9483e-01,\n",
      "          1.0850e-02,  1.2511e-01,  9.6902e-02,  6.5297e-02,  4.6687e-01,\n",
      "          6.9854e-01,  2.1205e-01,  3.7126e-01, -1.2726e-01,  5.2949e-01,\n",
      "         -1.2431e-01, -1.4811e-01,  7.8415e-02, -3.2775e-01, -1.1864e-01,\n",
      "         -5.7639e-01, -4.3344e-01, -3.0177e-02, -7.1930e-02, -4.8723e-01,\n",
      "          3.6879e-02,  9.7634e-02,  3.8697e-01,  3.6884e-01, -3.0068e-01,\n",
      "          1.9627e-01,  2.3411e-01, -4.0066e-01,  1.8983e-02,  1.0256e-01,\n",
      "          5.1296e-01, -1.0655e-02, -1.2201e-02, -1.6225e-01,  5.5245e-02,\n",
      "          1.3789e-01, -1.6537e-02,  2.2197e-01,  8.0461e-04,  1.9908e-01,\n",
      "          1.1554e-01, -3.0709e-01,  7.9228e-02,  3.7042e-02,  7.9527e-02,\n",
      "         -7.2193e-02,  3.1919e-01, -1.3665e-01,  3.1308e-03, -3.2798e-02,\n",
      "          7.8559e-02,  2.5155e-01, -1.2696e-01,  3.7694e-01,  3.0261e-01,\n",
      "          2.8097e-01,  2.9034e-02, -2.3659e-01,  1.7222e-02, -4.5497e-01,\n",
      "         -2.3916e-01, -1.3206e-01,  3.8253e-01, -2.3638e-01,  1.3567e-01,\n",
      "         -3.4041e-03,  2.3419e-01, -1.0192e-01,  1.8920e-01, -3.6342e-01,\n",
      "          2.3271e-01,  1.5313e-01, -2.9431e-02, -3.1857e-01,  2.2902e-01,\n",
      "          1.0070e-01,  2.9966e-01, -9.6829e-02,  2.3905e-01,  5.3846e-01,\n",
      "          2.4916e-02,  1.6470e-01, -2.6425e-01, -1.1208e-01,  1.1005e-01,\n",
      "         -1.4026e-01,  9.7286e-02, -1.2137e-01, -5.9932e-01, -2.3114e-01,\n",
      "         -1.5147e-01, -3.2412e-01, -2.6049e-01,  1.7619e-01,  2.5788e-01,\n",
      "         -6.6609e-03,  1.4388e-01, -2.8866e-01, -1.8930e-01, -2.6887e-01,\n",
      "         -1.8535e-01, -2.9743e-02,  4.3922e-01, -2.7669e-01, -3.0415e-01,\n",
      "          1.9994e-01, -5.7403e-02,  3.6575e-01, -1.9200e-01, -3.4733e-01,\n",
      "          3.7580e-01, -1.8142e-01, -1.9032e-02,  1.6103e-01, -6.0777e-02,\n",
      "         -4.7914e-01, -1.3529e-01,  3.2403e-01,  1.2026e-01,  1.8166e-01,\n",
      "          3.6035e-02,  3.9900e-01,  4.2658e-01, -3.0304e-01, -1.0528e-01,\n",
      "          1.8137e-01, -3.0496e-01,  1.3473e-01, -2.7872e-01,  1.9086e-01,\n",
      "         -3.9946e-01,  3.0015e-01, -6.0042e-02, -2.4077e-01,  1.7866e-01,\n",
      "         -8.1738e-03,  3.7958e-03, -6.3343e-02,  7.9060e-02, -2.7650e-01,\n",
      "         -6.5005e-03,  5.3993e-02,  1.4975e-01, -1.8934e-01,  1.1982e-01,\n",
      "         -4.8670e-01,  2.4081e-01, -2.7206e-01,  3.9036e-01, -3.3200e-01,\n",
      "          5.3622e-02, -8.3757e-02, -7.4043e-02, -2.6021e-01, -2.6256e-01,\n",
      "          2.2119e-01, -1.8307e-01,  4.9254e-02, -1.4742e-01, -3.2334e-01,\n",
      "         -2.7873e-01, -4.1281e-01, -3.7188e-01, -3.6123e-01,  4.6799e-02,\n",
      "         -1.8575e-01, -2.4266e-02,  6.3121e-01, -2.5878e-03,  4.9444e-02,\n",
      "         -1.1069e-02,  2.6400e-01, -9.0930e-02, -3.2871e-01,  3.1699e-02,\n",
      "         -2.1242e-01,  2.0928e-01,  4.4333e-02,  1.5355e-01,  8.8606e-02,\n",
      "         -7.9436e-02,  2.8053e-02, -1.3627e-01,  5.6006e-02, -2.8045e-02,\n",
      "         -6.6401e-01,  1.0298e-01,  5.5123e-02,  3.1205e-01,  1.1046e-01,\n",
      "          2.1519e-01,  2.0259e-01, -9.9091e-02,  3.8391e-01,  4.5106e-01,\n",
      "         -3.4776e-03, -2.3877e-01,  6.3824e-01,  1.7928e-01,  4.4310e-01,\n",
      "         -1.7291e-01, -1.9732e-01, -1.5926e-01, -1.6315e-01, -2.1875e-01,\n",
      "         -2.7945e-01,  3.3893e-02,  3.1627e-01,  2.0818e-01, -4.2835e-02,\n",
      "         -3.3566e-01,  1.9692e-01, -1.3162e-01,  9.0567e-02,  1.4923e-01,\n",
      "         -1.3294e-01, -1.4494e-01, -2.5725e-01, -2.4020e-01,  2.0879e-01,\n",
      "         -1.1896e-01, -1.2503e-01, -6.2465e-03, -3.2558e-02,  1.4967e-01,\n",
      "         -4.3432e-01, -3.6393e-01, -2.7830e-01,  6.2855e-02,  1.5501e-01,\n",
      "          2.0053e-01,  2.8603e-01,  2.1616e-01,  4.3625e-01,  2.2460e-01,\n",
      "          1.0574e-01, -1.6529e-01,  3.1245e-01, -3.9144e-02,  4.1623e-01,\n",
      "          6.6898e-02,  1.6608e-01, -1.6434e-01,  1.9909e-01,  4.4997e-01,\n",
      "          2.2514e-01,  1.9419e-01, -1.0384e-01,  6.9021e-02, -2.7413e-01,\n",
      "         -6.5024e-02,  1.5371e-01, -3.2786e-01,  2.9854e-01,  2.4532e-01,\n",
      "         -7.5659e-02,  7.4819e-02,  1.7473e-01, -1.7499e-02, -3.3474e-01,\n",
      "          2.4123e-01, -5.5291e-02, -1.0570e-03, -2.0918e-01, -1.2401e-01,\n",
      "          1.1788e-01, -2.8512e-01, -1.7100e-01, -2.5030e-01, -3.5941e-02,\n",
      "          2.0196e-01, -1.4019e-01, -1.0258e-01, -3.0505e-01,  2.4853e-03,\n",
      "         -5.6353e-02, -4.3407e-01, -1.4392e-02,  3.9311e-01,  5.0064e-01,\n",
      "          8.4781e-02,  2.7768e-01,  3.1730e-01, -5.3489e-01, -5.1133e-01,\n",
      "          1.1369e-01,  1.7782e-01,  1.5714e-01, -3.7348e-01, -1.8225e-01,\n",
      "         -7.5867e-02, -5.8559e-02,  1.4238e-01,  5.2649e-02,  3.5917e-01,\n",
      "         -9.5412e-02,  2.0527e-02, -4.2703e-02,  3.4183e-01,  6.7606e-02,\n",
      "         -2.8135e-01, -2.5887e-01, -1.7775e-01, -2.0042e-01, -3.6176e-01,\n",
      "         -5.5285e-01,  1.7985e-02,  1.3769e-01,  4.3481e-01, -3.7987e-01,\n",
      "         -1.0534e-01, -2.0353e-01,  1.6626e-01, -3.7523e-01,  4.2794e-01,\n",
      "          5.5929e-02, -5.1492e-01, -3.0919e-01,  2.6464e-01,  7.9629e-03,\n",
      "          1.0430e-02, -5.4045e-01, -2.6930e-01, -4.6368e-01, -1.3638e-01,\n",
      "         -1.0723e-01, -1.3671e-01, -2.4232e-01,  1.1775e-01, -9.6683e-02,\n",
      "          4.3224e-02, -1.2450e-01, -2.2660e-02,  5.3971e-02, -4.6862e-01,\n",
      "         -3.4529e-01,  1.9439e-01,  9.8718e-03, -1.5412e-01,  3.6466e-02,\n",
      "          1.3907e-01, -5.2997e-01, -4.4272e-01, -1.1411e-01,  6.9400e-03,\n",
      "          2.4152e-02,  1.0749e-01, -3.7600e-01, -4.3789e-01,  1.3209e-01,\n",
      "         -3.4168e-01,  1.4954e-02, -3.5419e-01, -1.7535e-01,  2.7512e-01,\n",
      "          1.4636e-01,  1.9167e-01,  2.3997e-02,  4.6361e-02,  2.2369e-01,\n",
      "         -1.5512e-01, -1.5841e-01, -2.0635e-01,  1.8982e-01, -8.0768e-02,\n",
      "         -3.4374e-01,  1.9730e-02, -4.9509e-01, -3.8921e-01, -4.8877e-01,\n",
      "         -3.5411e-01,  1.9352e-01,  1.0091e-01, -2.3881e-01,  1.0145e-01,\n",
      "         -6.5021e-02, -3.1168e-02,  3.6666e-03,  5.8042e-01,  1.8786e-01,\n",
      "          1.5478e-01, -1.7902e-01,  3.1532e-01,  4.0532e-01,  1.1772e-01,\n",
      "         -1.1278e-01,  1.8992e-01,  3.3426e-01,  3.1379e-01,  9.5130e-02,\n",
      "          2.4814e-01,  1.0504e-01,  1.4919e-01, -4.0000e-02,  1.7069e-01,\n",
      "         -1.9687e-01,  3.8147e-01,  7.9074e-02, -2.3294e-01, -1.9506e-01,\n",
      "         -6.2730e-02,  2.5685e-01,  2.9516e-01,  2.0145e-01,  1.1452e-01,\n",
      "          4.1989e-02, -9.9369e-02, -9.1908e-02, -5.6347e-01,  1.2470e-01,\n",
      "          4.4552e-01,  9.2193e-02, -8.8708e-02,  1.3289e-01, -7.7865e-02,\n",
      "          2.5055e-01, -8.3188e-03, -4.3781e-01, -1.6334e-01,  3.4930e-01,\n",
      "         -1.3244e-01, -1.0090e-01, -6.1744e-01,  1.3946e-01,  2.7170e-01,\n",
      "          2.2484e-01, -1.7196e-01,  5.8781e-02,  1.1966e-01, -5.6267e-01,\n",
      "          1.8582e-01, -5.0520e-01, -2.9874e-01, -1.0347e-01,  1.1296e-01,\n",
      "          3.5229e-01,  1.6109e-01, -1.5227e-01, -2.5074e-01,  2.6866e-01,\n",
      "          2.3924e-01,  5.0164e-01,  4.0658e-02,  2.5768e-02, -1.5767e-01,\n",
      "          4.1183e-01, -1.6247e-01,  2.4292e-01, -3.5967e-01,  2.0954e-01,\n",
      "         -7.8037e-01,  3.0145e-01, -6.9978e-02, -6.4666e-03,  2.6244e-02,\n",
      "          1.9928e-01,  2.1723e-01,  3.3210e-01,  2.5844e-01, -1.0700e-01,\n",
      "         -2.7617e-01, -5.3220e-01, -3.6204e-03,  2.5385e-01,  1.0670e-01,\n",
      "         -8.8398e-02,  3.5048e-02,  3.0446e-01,  5.5448e-02,  2.2992e-01,\n",
      "         -2.2974e-01, -2.1943e-01,  3.1617e-01, -1.4068e-02,  1.6548e-01,\n",
      "          1.4320e-01, -2.9368e-01,  2.9147e-01, -5.1976e-02,  9.9152e-02,\n",
      "          6.0413e-02, -3.4605e-01,  9.5510e-03, -2.7287e-01, -1.1727e-01,\n",
      "          1.0388e-01, -4.5341e-02,  2.0661e-01, -3.9667e-02,  3.0549e-01,\n",
      "         -4.7523e-01,  9.6033e-02, -1.1333e-01,  2.1988e-02, -2.1914e-01,\n",
      "         -1.3909e-01,  2.2141e-01, -9.9470e-02,  8.5582e-03,  1.3205e-01,\n",
      "          4.3462e-01, -1.6573e-02, -3.9391e-01,  4.2985e-01,  6.1222e-02,\n",
      "          4.9025e-01,  3.0929e-01, -7.5994e-02,  1.4849e-01, -1.0830e-01,\n",
      "          4.1936e-01, -4.3910e-02,  1.3169e-02,  1.4147e-01, -6.1329e-02,\n",
      "         -1.5455e-01, -1.7906e-01,  1.1028e-01, -9.6810e-02,  9.3776e-02,\n",
      "          7.0798e-02, -3.8064e-02, -1.7130e-01, -8.3653e-02, -1.0167e-01,\n",
      "         -2.4790e-01,  1.1354e-01,  1.3238e-01,  2.0132e-01, -4.5136e-01,\n",
      "          1.4156e-01,  2.2040e-01,  3.4390e-01,  2.9052e-01,  1.3760e-01,\n",
      "          1.5432e-01, -2.0508e-01, -1.6036e-01, -1.1241e-01,  1.8247e-02,\n",
      "          2.1077e-01, -3.6149e-01,  2.3225e-01, -1.6923e-01,  1.7566e-01,\n",
      "         -1.2947e-02, -1.4993e-01,  5.7094e-01, -1.4767e-01,  4.5306e-01,\n",
      "          9.2942e-02, -1.3440e-01, -2.2741e-01,  4.1248e-02,  2.0930e-02,\n",
      "         -5.5870e-03, -4.5817e-02,  3.7790e-01,  2.9529e-03, -2.5197e-01,\n",
      "         -6.8939e-02,  6.2858e-02, -1.0025e-01,  1.7656e-01, -5.6491e-02,\n",
      "          3.6634e-01, -3.5385e-01, -2.6260e-01, -1.1489e-01, -1.0497e-01,\n",
      "          9.0118e-02, -2.1335e-01,  2.5921e-01,  1.4231e-01,  4.3490e-02,\n",
      "         -2.8338e-02,  2.9121e-01,  2.2440e-01,  2.7551e-01,  4.0879e-01,\n",
      "          1.6077e-01, -1.7329e-01,  6.5297e-02, -4.1917e-02, -8.8193e-02,\n",
      "         -2.3934e-01, -3.5328e-01, -8.1976e-02,  2.1148e-01, -7.4901e-02,\n",
      "         -1.4352e-01, -2.2370e-01, -1.6624e-01,  9.2973e-02, -2.4548e-01,\n",
      "         -3.0474e-02, -3.4516e-01,  2.5432e-01,  2.8543e-02, -3.6707e-01,\n",
      "          1.1266e-01,  1.0434e-01, -2.6103e-01, -1.1630e-01,  9.3457e-02,\n",
      "          2.0610e-01, -5.8774e-01, -4.6175e-02, -2.7515e-02, -2.3289e-01,\n",
      "          2.8867e-03,  4.0546e-01, -3.2485e-01, -9.9608e-02,  4.2594e-01,\n",
      "         -5.1187e-02,  1.3774e-02, -1.7888e-02,  1.3899e-02,  6.5010e-02,\n",
      "         -1.7764e-02, -2.3687e-04, -1.3646e-02,  2.2156e-01, -2.3065e-01,\n",
      "         -1.7093e-01, -1.6521e-01, -1.7842e-01,  2.2679e-01, -1.9755e-01,\n",
      "          2.8982e-01, -7.9654e-02, -1.4133e-01, -1.2944e-01, -2.9684e-01,\n",
      "         -3.4415e-02, -4.2142e-01, -2.0470e-01,  2.3020e-01, -2.4734e-01,\n",
      "          2.4459e-01,  5.2852e-02,  3.1757e-01,  1.9707e-02, -3.3774e-01,\n",
      "         -1.0423e-01,  1.6013e-01, -3.5281e-01,  4.3361e-01, -4.4368e-01,\n",
      "         -1.9506e-01, -2.1560e-01, -1.8979e-01, -1.4091e-01, -2.1010e-01,\n",
      "         -4.0213e-01, -2.7511e-01,  1.1677e-01,  6.3437e-01, -5.0704e-03,\n",
      "         -4.1842e-01, -1.6866e-01, -7.8628e-02, -1.2451e-01, -8.4124e-02,\n",
      "         -4.3038e-02, -1.7938e-01,  2.5171e-01,  4.3644e-01,  2.1442e-02,\n",
      "         -1.4359e-01, -2.9443e-02,  1.3510e-01, -3.0431e-01,  4.6061e-02,\n",
      "         -1.6879e-01,  3.3292e-01,  3.3978e-01, -9.0060e-02, -5.2644e-02,\n",
      "          5.3350e-01, -1.4740e-02, -2.1006e-01,  9.0608e-02,  1.3739e-01,\n",
      "         -3.2172e-01,  8.2475e-02, -1.7069e-01,  3.4230e-01, -8.9073e-04,\n",
      "          4.3763e-01,  2.1447e-01, -1.6729e-01, -4.1368e-01,  4.0725e-01,\n",
      "         -2.7258e-01, -4.0144e-01, -1.2018e-01,  2.6030e-01, -1.4422e-02,\n",
      "          2.1057e-01,  1.4345e-01,  6.1927e-02, -2.1991e-01,  1.5371e-01,\n",
      "          5.1140e-01, -6.0725e-02,  2.6705e-01,  9.2632e-02,  1.6727e-01,\n",
      "         -7.5742e-02, -7.3171e-01,  2.6865e-01, -2.9859e-01, -3.1235e-01,\n",
      "         -1.9662e-01,  3.5026e-02,  3.0400e-01, -2.4983e-01,  1.8570e-01,\n",
      "         -4.4265e-01,  3.0378e-02,  3.3160e-01, -2.8134e-01, -2.7489e-01,\n",
      "          1.0614e-01,  4.1240e-01,  2.9221e-01, -2.6196e-02, -3.8231e-02,\n",
      "          2.2506e-01,  1.3574e-01,  3.8739e-02,  1.6976e-01,  8.6008e-02,\n",
      "          2.4330e-01,  4.3380e-02, -5.4296e-02, -4.8275e-02, -2.3145e-01,\n",
      "          2.2245e-01, -1.3150e-02, -8.2272e-02, -8.6586e-02, -2.2933e-01,\n",
      "         -2.2479e-01,  2.1442e-01,  5.2467e-01, -8.4016e-02,  1.8363e-01,\n",
      "         -4.7010e-01, -2.5839e-01,  2.5644e-01,  1.4970e-02, -8.9573e-02,\n",
      "         -9.6452e-02, -6.2269e-01,  7.1078e-02,  7.0144e-02, -2.1416e-01,\n",
      "         -8.3042e-03, -5.8335e-02, -3.3579e-01,  3.4585e-01, -7.5770e-02,\n",
      "         -1.8543e-01,  1.3167e-01,  4.5110e-01, -3.7353e-01,  1.8475e-02,\n",
      "         -3.6196e-01, -1.5279e-01, -3.9876e-01, -2.0197e-01,  1.4877e-01,\n",
      "          2.9482e-01, -1.3824e-01,  1.6385e-01,  7.7903e-02,  3.0391e-01,\n",
      "          3.1238e-01, -1.1499e-01,  3.3445e-01,  1.3184e-01, -8.3519e-02,\n",
      "          3.0881e-01,  1.5775e-01, -2.4972e-01,  5.3796e-02,  3.3587e-01,\n",
      "          2.5209e-01, -1.5660e-01, -5.6928e-02,  3.3689e-01, -6.7154e-02,\n",
      "         -5.5231e-02, -1.8375e-01, -1.8094e-01, -3.2967e-01,  2.1620e-02,\n",
      "         -2.3018e-01,  1.3072e-01, -7.4443e-02, -2.4685e-01, -1.4941e-02,\n",
      "         -9.2372e-02,  1.7690e-01,  1.7002e-01, -2.9294e-01,  1.3630e-01,\n",
      "          3.9320e-01, -2.4346e-01, -1.9781e-01,  2.2099e-01,  1.8607e-02,\n",
      "         -3.1346e-01, -3.6868e-02, -2.4328e-01, -2.8929e-01, -1.1936e-02]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "VGG16=[64,64,'M',128,128,'M',256,256,256,'M',512,512,512,'M',512,512,512,'M']\n",
    "class VGG_Net(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(VGG_Net, self).__init__()\n",
    "        self.in_channels=in_channels\n",
    "        self.conv_layers=self.create_conv_layer(VGG16)\n",
    "        self.fully_connected_layers=nn.Sequential(\n",
    "            nn.Linear(512*7*7,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096,num_classes)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x=self.conv_layers(x)\n",
    "        print(x.shape)\n",
    "        x=x.reshape(x.shape[0],-1)\n",
    "        print(f\"X in Forward after reshape:{x} \")\n",
    "        x=self.fully_connected_layers(x)\n",
    "        print(f\"In forward layer: {x}\")\n",
    "        return x\n",
    "    def create_conv_layer(self, architecture):\n",
    "        layers=[]\n",
    "        in_channels=self.in_channels\n",
    "        \n",
    "        for x in architecture:\n",
    "            if type(x)==int:\n",
    "                out_channels=x\n",
    "                \n",
    "                layers +=[nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
    "                         nn.BatchNorm2d(x),\n",
    "                         nn.ReLU()]\n",
    "                in_channels=x\n",
    "            elif x=='M':\n",
    "                layers +=[nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))]\n",
    "        print(f\"Creating Conv_layers: {layers} \\n\")\n",
    "        return nn.Sequential(*layers)\n",
    "model=VGG_Net(in_channels=3, num_classes=1000)\n",
    "x=torch.randn(1,3,224,224)\n",
    "print(model)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
